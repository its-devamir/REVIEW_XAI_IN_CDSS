# هوش مصنوعی قابل توضیح در سیستم‌های پشتیبان تصمیم بالینی (CDSS)

این مخزن همراه با ویدیو ارائه و Jupyter Notebook پروژه است که کاربرد **Explainable AI (XAI)** در سیستم‌های پشتیبان تصمیم بالینی را نشان می‌دهد. این پروژه بر اساس مقاله مروری زیر انجام شده است:

**مقاله:** [Explainable AI in Clinical Decision Support Systems: A Systematic Review](https://www.mdpi.com/2227-9032/13/17/2154)

## آنچه در این پروژه انجام شده:

1. **مرور کامل مقاله** و استخراج مفاهیم کلیدی، روش‌ها و حوزه‌های بالینی کاربرد XAI.  
2. **ایجاد یک دیتاست شبیه‌سازی شده بالینی** با ویژگی‌های بیماران برای نشان دادن مدل‌های یادگیری ماشین در CDSS.  
3. **پیاده‌سازی دو مدل:**  
   - **Random Forest** (مدل جعبه سیاه)  
   - **Logistic Regression** (مدل قابل تفسیر)  
4. **نمایش توضیح‌های کلی و محلی (Global & Local Explanations)** با استفاده از تکنیک‌های XAI:  
   - SHAP  
   - LIME  
   - Grad-CAM (برای داده‌های تصویری به‌صورت مفهومی)  
   - Attention visualization (به‌صورت مفهومی)  
5. **ضبط ویدیو ارائه** که مدل‌ها، روش‌های XAI و کاربرد آن‌ها در CDSS را گام‌به‌گام توضیح می‌دهد.  
6. **قرار دادن PDF مقاله** در کنار نوت‌بوک برای مراجعه مستقیم.  

## هدف پروژه

نشان دادن اینکه چگونه XAI می‌تواند اعتماد، شفافیت و کاربردپذیری مدل‌های هوش مصنوعی را در سیستم‌های پشتیبان تصمیم بالینی افزایش دهد و فاصله بین مدل‌های جعبه سیاه و محیط واقعی پزشکی را کاهش دهد.

---

می‌توانید نوت‌بوک را باز کنید و ویدیو ارائه را مشاهده کنید تا گام‌به‌گام روش‌ها و یافته‌های مقاله را ببینید.
